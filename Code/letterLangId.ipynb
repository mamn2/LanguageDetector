{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fileReader import readTrainingFile, readTestFile\n",
    "import math\n",
    "import re\n",
    "\n",
    "def trainClassifier():\n",
    "\n",
    "    italian = readTrainingFile('../Data/Input/LangId.train.Italian', \"ital\")\n",
    "    french = readTrainingFile('../Data/Input/LangId.train.French', \"fra\")\n",
    "    english = readTrainingFile('../Data/Input/LangId.train.English', \"eng\")\n",
    "\n",
    "    bigrams = {}\n",
    "\n",
    "    for letter in range(0, len(english) - 1):\n",
    "        bigram = (english[letter], english[letter + 1])\n",
    "        if bigram in bigrams:\n",
    "            bigrams[bigram][0] += 1\n",
    "        else:\n",
    "            bigrams[bigram] = [1, 0, 0]\n",
    "\n",
    "    for letter in range(0, len(italian) - 1):\n",
    "        bigram = (italian[letter], italian[letter + 1])\n",
    "        if bigram in bigrams:\n",
    "            bigrams[bigram][1] += 1\n",
    "        else:\n",
    "            bigrams[bigram] = [0, 1, 0]\n",
    "\n",
    "    for letter in range(0, len(french) - 1):\n",
    "        bigram = (french[letter], french[letter + 1])\n",
    "        if bigram in bigrams:\n",
    "            bigrams[bigram][2] += 1\n",
    "        else:\n",
    "            bigrams[bigram] = [0, 0, 1]\n",
    "\n",
    "    probBigramGivenClass = {}\n",
    "    uniqueBigrams = len(bigrams)\n",
    "    laplace = 1.0\n",
    "\n",
    "    for bigram in bigrams:\n",
    "        probBigramGivenClass[(bigram, 0)] = math.log((bigrams[bigram][0] + laplace) / (len(english) + laplace * uniqueBigrams))\n",
    "        probBigramGivenClass[(bigram, 1)] = math.log((bigrams[bigram][1] + laplace) / (len(italian) + laplace * uniqueBigrams))\n",
    "        probBigramGivenClass[(bigram, 2)] = math.log((bigrams[bigram][2] + laplace) / (len(french) + laplace * uniqueBigrams))\n",
    "\n",
    "    numBigramsPerClass = (len(english), len(italian), len(french))\n",
    "\n",
    "    return probBigramGivenClass, uniqueBigrams, numBigramsPerClass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def naiveBayesClassifer():\n",
    "    laplace = 1.0\n",
    "    probBigramGivenClass, uniqueBigrams, numBigramsPerClass = trainClassifier()\n",
    "    count = 0\n",
    "\n",
    "    classifiedLabels = []\n",
    "\n",
    "    for line in readTestFile():\n",
    "        probEngGivenWord = math.log(1.0/3.0)\n",
    "        probItalGivenWord = math.log(1.0/3.0)\n",
    "        probFraGivenWord = math.log(1.0/3.0)\n",
    "        for letter in range(0, len(line) - 1):\n",
    "            bigram = (line[letter], line[letter + 1])\n",
    "            if (bigram, 0) not in probBigramGivenClass:\n",
    "                continue\n",
    "            if probBigramGivenClass[(bigram, 0)] == 0:\n",
    "                probEngGivenWord += math.log(laplace / (numBigramsPerClass[0] + uniqueBigrams * laplace))\n",
    "            else:\n",
    "                probEngGivenWord += probBigramGivenClass[(bigram, 0)]\n",
    "            if probBigramGivenClass[(bigram, 1)] == 0:\n",
    "                probItalGivenWord += math.log(laplace / (numBigramsPerClass[1] + uniqueBigrams * laplace))\n",
    "            else:\n",
    "                probItalGivenWord += probBigramGivenClass[(bigram, 1)]\n",
    "            if probBigramGivenClass[(bigram, 2)] == 0:\n",
    "                probFraGivenWord += math.log(laplace / (numBigramsPerClass[2] + uniqueBigrams * laplace))\n",
    "            else:\n",
    "                probFraGivenWord += probBigramGivenClass[(bigram, 2)]\n",
    "\n",
    "        if probEngGivenWord >= probItalGivenWord and probEngGivenWord >= probFraGivenWord:\n",
    "            classifiedLabels.append(\"English\")\n",
    "        elif probItalGivenWord >= probEngGivenWord and probItalGivenWord >= probFraGivenWord:\n",
    "            classifiedLabels.append(\"Italian\")\n",
    "        else:\n",
    "            classifiedLabels.append(\"French\")\n",
    "\n",
    "    return classifiedLabels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "def test_accuracy():\n",
    "\n",
    "    predicted_list = naiveBayesClassifer()\n",
    "    actual_list = []\n",
    "\n",
    "    with open('../Data/Validation/labels.sol', 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            line = re.sub('[0-9]+ (.*)\\n', '\\\\1', line)\n",
    "            actual_list.append(line)\n",
    "\n",
    "    correct = 0.0\n",
    "\n",
    "    with open('../Data/Output/letterLangId.out', 'w') as file:\n",
    "        for i in range(0, len(predicted_list)):\n",
    "            file.write(predicted_list[i] + '\\n')\n",
    "            if predicted_list[i] == actual_list[i]:\n",
    "                correct += 1.0\n",
    "    \n",
    "\n",
    "    return correct / len(predicted_list)\n",
    "\n",
    "test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
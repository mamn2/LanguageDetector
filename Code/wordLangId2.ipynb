{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fileReader import readTrainingFile, readTestFile\n",
    "import math \n",
    "import re\n",
    "\n",
    "def goodTuring(bigrams):\n",
    "    \n",
    "    Cstar = []\n",
    "    Nc = []\n",
    "\n",
    "    for bigram in bigrams:\n",
    "        count = bigrams[bigram]\n",
    "        if count in Cstar:\n",
    "            Nc[Cstar.index(count)] += 1\n",
    "        else:\n",
    "            Cstar.append(count) # records what the count is\n",
    "            Nc.append(1) # 1 occurence\n",
    "\n",
    "    # Pstar(unseen) = N_1 / N\n",
    "    bigrams[0] = Nc[Cstar.index(1)] / (len(bigrams.keys()) * len(bigrams.keys()) - sum(Nc))\n",
    "\n",
    "    # Linear regression technique learned from https://realpython.com/linear-regression-in-python/\n",
    "    # Given that we could not use any of the packages, I just followed the guide for how LinReg works in general\n",
    "\n",
    "    NcLog = [math.log(x) for x in Nc]\n",
    "    xmean = sum(Cstar) * 1.0 / len(Cstar) \n",
    "    ymean = sum(NcLog) * 1.0 / len(NcLog)\n",
    "    covariance = sum([(Cstar[i] - xmean) * (NcLog[i] - ymean) for i in range(len(Cstar))])\n",
    "    variance = sum([(x - xmean) ** 2 for x in Cstar])\n",
    "\n",
    "    # b_1 and b_0 from a linear equation\n",
    "    b_1 = covariance / variance\n",
    "    b_0 = ymean - b_1 * xmean\n",
    "\n",
    "    for bigram in bigrams.keys():\n",
    "        count = bigrams[bigram]\n",
    "        if count in Cstar:\n",
    "            if count + 1 in Cstar:\n",
    "                bigrams[bigram] = (Nc[Cstar.index(count + 1)] * (count + 1) / Nc[Cstar.index(count)])\n",
    "            else:\n",
    "                bigrams[bigram] = count + math.exp(b_0 + b_1 * (count + 1)) * (count + 1) / math.exp((b_0 + b_1 * count)) / Nc[Cstar.index(count)]\n",
    "\n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def trainClassifier():\n",
    "\n",
    "    italian = readTrainingFile('../Data/Input/LangId.train.Italian', \"ital\")\n",
    "    french = readTrainingFile('../Data/Input/LangId.train.French', \"fra\")\n",
    "    english = readTrainingFile('../Data/Input/LangId.train.English', \"eng\")\n",
    "    \n",
    "    eng_bigrams = {}\n",
    "    eng_words = {}\n",
    "    englishSplit = english.split()\n",
    "    for word in range(0, len(englishSplit) - 1):\n",
    "        bigram = (englishSplit[word], englishSplit[word + 1])\n",
    "        if bigram in eng_bigrams:\n",
    "            eng_bigrams[bigram] += 1\n",
    "        else:\n",
    "            eng_bigrams[bigram] = 1\n",
    "    for word in englishSplit:\n",
    "        if word in eng_words:\n",
    "            eng_words[word] += 1\n",
    "        else:\n",
    "            eng_words[word] = 1\n",
    "    eng_bigrams = goodTuring(eng_bigrams)\n",
    "    \n",
    "    ital_bigrams = {}\n",
    "    ital_words = {}\n",
    "    italSplit = italian.split()\n",
    "    for word in range(0, len(italSplit) - 1):\n",
    "        bigram = (italSplit[word], italSplit[word + 1])\n",
    "        if bigram in ital_bigrams:\n",
    "            ital_bigrams[bigram] += 1\n",
    "        else:\n",
    "            ital_bigrams[bigram] = 1\n",
    "    for word in italSplit:\n",
    "        if word in ital_words:\n",
    "            ital_words[word] += 1\n",
    "        else:\n",
    "            ital_words[word] = 1\n",
    "    ital_bigrams = goodTuring(ital_bigrams)\n",
    "\n",
    "    fra_bigrams = {}\n",
    "    fra_words = {}\n",
    "    fraSplit = french.split()\n",
    "    for word in range(0, len(fraSplit) - 1):\n",
    "        bigram = (fraSplit[word], fraSplit[word + 1])\n",
    "        if bigram in fra_bigrams:\n",
    "            fra_bigrams[bigram] += 1\n",
    "        else:\n",
    "            fra_bigrams[bigram] = 1\n",
    "    for word in fraSplit:\n",
    "        if word in fra_words:\n",
    "            fra_words[word] += 1\n",
    "        else:\n",
    "            fra_words[word] = 1\n",
    "    fra_bigrams = goodTuring(fra_bigrams)\n",
    "\n",
    "    return (eng_bigrams, ital_bigrams, fra_bigrams, eng_words, ital_words, fra_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def naiveBayesClassifier():\n",
    "\n",
    "    eng_bigrams, ital_bigrams, fra_bigrams, eng_words, ital_words, fra_words = trainClassifier()\n",
    "\n",
    "    classifiedLabels = []\n",
    "\n",
    "    for line in readTestFile():\n",
    "        probEngGivenWord = math.log(1.0/3.0)\n",
    "        probItalGivenWord = math.log(1.0/3.0)\n",
    "        probFraGivenWord = math.log(1.0/3.0)\n",
    "        lineSplit = line.split()\n",
    "        uniqueBigrams = len(eng_bigrams) + len(ital_bigrams)+ len(fra_bigrams)\n",
    "        for word in range(0, len(lineSplit) - 1):\n",
    "            bigram = (lineSplit[word], lineSplit[word + 1])\n",
    "\n",
    "            if bigram not in eng_bigrams:\n",
    "                probEngGivenWord += math.log(eng_bigrams[0])\n",
    "            else:\n",
    "                probEngGivenWord += math.log(eng_bigrams[bigram] / eng_words[bigram[0]])\n",
    "            if bigram not in ital_bigrams:\n",
    "                probItalGivenWord += math.log(ital_bigrams[0])\n",
    "            else:\n",
    "                probItalGivenWord += math.log(ital_bigrams[bigram] / ital_words[bigram[0]])\n",
    "            if bigram not in fra_bigrams:\n",
    "                probFraGivenWord += math.log(fra_bigrams[0])\n",
    "            else:\n",
    "                probFraGivenWord += math.log(fra_bigrams[bigram] / fra_words[bigram[0]])\n",
    "\n",
    "        if probEngGivenWord >= probItalGivenWord and probEngGivenWord >= probFraGivenWord:\n",
    "            classifiedLabels.append(\"English\")\n",
    "        elif probItalGivenWord >= probEngGivenWord and probItalGivenWord >= probFraGivenWord:\n",
    "            classifiedLabels.append(\"Italian\")\n",
    "        else:\n",
    "            classifiedLabels.append(\"French\")\n",
    "            \n",
    "    return classifiedLabels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9833333333333333"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "def test_accuracy():\n",
    "\n",
    "    predicted_list = naiveBayesClassifier()\n",
    "    actual_list = []\n",
    "\n",
    "    with open('../Data/Validation/labels.sol', 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            line = re.sub('[0-9]+ (.*)\\n', '\\\\1', line)\n",
    "            actual_list.append(line)\n",
    "\n",
    "    correct = 0.0\n",
    "\n",
    "    with open('../Data/Output/wordLangId2.out', 'w') as file:\n",
    "        for i in range(0, len(predicted_list)):\n",
    "            file.write(predicted_list[i] + '\\n')\n",
    "            if predicted_list[i] == actual_list[i]:\n",
    "                correct += 1.0\n",
    "    \n",
    "\n",
    "    return correct / len(predicted_list)\n",
    "\n",
    "\n",
    "test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}